---
title: "Proyecto final Ciencia de Datos con R:\nMicro, pequeñas y medianas empresas en el Uruguay."
title-block-banner: true
author: "Gonzalo Ruiz <gonzaaruizz22@gmail.com>"
format:
  pdf:
    toc: true
    toc-title: "Indice"
    echo: false
  html:
    toc: true
    toc-title: "Indice"
    code-fold: true
execute: 
  warning: false
bibliography: references.bib
bibliographystyle: apa
---

## Introducción

## Datos, datos y más datos

Para el siguiente análisis utilizaremos datos de múltiple fuentes que nos ayudarán a explicar el fenómeno de las empresas de distinto tamaño en Uruguay a través de variables indicadoras de la situación económica del país y de variables relacionadas a las empresas mencionadas.

Las fuentes utilizadas fueron extraídas de:

-   @ande2024
-   Informe IDERE-UY (@idereuy2024)
-   Observatorio Territorio Uruguay -- OPP (@opp2018)

### Descripción de variables

| Variable | Descripción |
|-------------------------------|-----------------------------------------|
| anio | Año de referencia de la observación. |
| departamento | Nombre del departamento (en Uruguay) donde se registra la información. |
| tamanio | Clasificación del tamaño de las empresas (ej. micro, pequeña, mediana, etc.). |
| sector | Sector económico al que pertenece la empresa (ej. industria, servicios, etc.). |
| n_empresas | Número total de empresas registradas. |
| n_nacimientos | Número total de nuevas empresas creadas. |
| n_muertes | Número de empresas que dejaron de operar. |
| alfabetismo | Tasa de alfabetismo. |
| accesos_a_estudios_terciarios | Población entre 25 y 65 años que accede a estudios terciarios(%). |
| anios_de_educacion_promedio | Promedio de años de educación de la población de 25 años y más. |
| promocion_educacion_media_cb | Porcentaje de promoción en ciclo básico de educación media pública. |
| pobreza | Personas en hogares en situación de pobreza (%). |
| informalidad | Informalidad de los ocupados (%). |
| desempleo_en_jovenes | Cociente entre tasa de desempleo de jóvenes (14-29 años) y tasa general. |
| gini | Coeficiente de Gini (ingreso de los hogares). |
| acceso_a_internet | Hogares con conexión a internet (%). |
| ingresos_de_los_hogares | Relación entre el ingreso per cápita de los hogares del departamento y el valor para el país. |
| tasa_de_desempleo | Tasa de desempleo. |
| porcentaje_de_personal_presupuestado_en_la_intendencia | Porcentaje de personal presupuestado en el total de funcionarios de los gobiernos departamentales. |
| part_act_econ | Participación porcentual del departamento en la actividad económica país. |

## Ánalisis exploratorio

Al trabajar con datos es natural hacerse preguntas sobre la composición y características de los mismos, es en éste siguiente análisis que intentaremos dar respuestas de manera visual y con medidas de resúmenes numéricas para familiarizarnos con nuestra base de datos.

```{r}
#| label: librerias
#| include: false
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(modeltime)
options(repr.plot.width=30, repr.plot.height=18)
```

```{r}
#| label: datasets
# Participacion en la actividad economica
act_econ_df <- read_delim(
  here::here("data/proyecto/indicadores/participacion-departamental-actividad-economica.csv"),
  show_col_types = FALSE
) |>
  pivot_longer(cols = where(is.numeric), names_to="anio", values_to="part_act_econ") |>
  mutate(anio = as.character(anio), departamento = tolower(trimws(chartr("áéíóú", "aeiou", departamento))))

# Indicadores de desarrollo socio-economico
idere_df <- readxl::read_xlsx(
  here::here("data/proyecto/indicadores/idere.xlsx"),
  sheet = 1,
) |>
  rename_with(~ tolower(gsub(" ", "_", .x, fixed=T))) |>
  rename(
    gini="gini_(distribución_del_ingreso)",
    ingresos_de_los_hogares="ingresos_de_los_hogares_(en_proporción_del_promedio_país)"
  ) |>
  rename_with(~ chartr("áéíóú", "aeiou", .x)) |>
  rename_with(~ gsub("ñ", "ni", .x, fixed=T)) |>
  filter(!departamento %in% c("Promedio", "Máximo", "Mínimo")) |>
  select(
    departamento,
    anio,
    alfabetismo,
    accesos_a_estudios_terciarios,
    anios_de_educacion_promedio,
    promocion_educacion_media_cb,
    pobreza,
    informalidad,
    desempleo_en_jovenes,
    gini,
    acceso_a_internet,
    ingresos_de_los_hogares,
    tasa_de_desempleo,
    porcentaje_de_personal_presupuestado_en_la_intendencia
  ) |>
  mutate(anio = as.character(anio), departamento = tolower(trimws(chartr("áéíóú", "aeiou", departamento))))

pymes_df <- list.files("data/proyecto/pymes/n-empresas", full.names = T) |>
  lapply(readxl::read_xlsx) |>
  bind_rows() |>
  rename_with(~ tolower(gsub("ñ", "ni", .x, fixed=T))) %>%
  rename(n_empresas="valor") |>
  select(-indicador) |>
  left_join(
    list.files("data/proyecto/pymes/n-nacimientos", full.names = T) |>
    lapply(readxl::read_xlsx) |>
    bind_rows() |>
    rename_with(~ tolower(gsub("ñ", "ni", .x, fixed=T))) |>
    rename(n_nacimientos="valor") |>
    select(-indicador),
    by=c("anio", "departamento", "tamanio", "sector")
  ) |>
  left_join(
    list.files("data/proyecto/pymes/n-muertes", full.names = T) |>
    lapply(readxl::read_xlsx) |>
    bind_rows() |>
    rename_with(~ tolower(gsub("ñ", "ni", .x, fixed=T))) |>
    rename(n_muertes="valor") |>
    select(-indicador),
    by=c("anio", "departamento", "tamanio", "sector")
  ) |>
  mutate(anio = as.character(anio)) |>
  mutate(across(where(is.character), ~ tolower(trimws(chartr("áéíóú", "aeiou", .x))))) |>
  left_join(
    idere_df,
    by=c("departamento", "anio")
  ) |>
  left_join(
    act_econ_df,
    by=c("departamento", "anio")
  ) |>
  mutate(departamento = as.factor(departamento), sector = as.factor(sector), tamanio = factor(tamanio, levels=tamanio |> unique() |> sort(), ordered=T))
```

-   ¿Cuál es la dimensión de nuestro Dataset?

Tenemos un Dataset con `{r} nrow(pymes_df)` observaciones y `{r} length(colnames(pymes_df))` variables.

-   ¿Existen duplicados?

Tenemos `{r} nrow(pymes_df)` observaciones y si descartamos los duplicados nos queda en: `{r} pymes_df |> distinct() |> nrow()`.

-   ¿Cómo está armado nuestro DataFrame? ¿qué variables contiene? Y ejemplos de observaciones.

    -   Esquema

```{r}
#| label: glimpse
pymes_df |> glimpse()
```

```         
-   Primeras 6 filas
```

```{r}
#| label: head
pymes_df |> head()
```

-   Últimas 6 filas

```{r}
#| label: tail
pymes_df |> tail()
```

-   6 filas aleatorias

```{r}
#label: rand6
pymes_df |> sample_n(6)
```

Es fácil de observar que existen variables numéricas que contienen observaciones de tipo `character` representando a valores faltantes y, al mismo tiempo, también observamos la existencia de valores `NA`.

Entonces, nos preguntamos:

-   ¿Cuál es el porcentaje de datos faltantes existe por cadá variable?

::: callout-note
Como se vio en las observaciones seleccionadas, existen datos faltantes representados con texto por lo que necesitaremos pre-procesar esas columnas y normalizar la representación de un dato faltante como `NA`. Luego formalizaremos este pre-procesamiento como parte del flujo pre-modelado.
:::

```{r}
#| label: pct-faltantes
pymes_df |>
  mutate(across(starts_with("n_"), ~ as.numeric(na_if(.x, "SIN DATOS")))) |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  summarise_all(~ sum(is.na(.x))) |>
  pivot_longer(cols=everything(), names_to="variable", values_to="cant_faltantes") |>
  mutate(pct_faltantes = cant_faltantes * 100 / nrow(pymes_df)) |>
  mutate(variable = fct_reorder(variable, cant_faltantes)) |>
  ggplot(aes(x=variable, y=pct_faltantes)) +
  geom_col(fill="skyblue") +
  labs(title="Porcentajes de datos faltantes por variable.", x="Variable", y="Porcentaje de faltantes") +
  coord_flip()
```

-   ¿Y si subimos un nivel de agregación ignorando el sector?

```{r}
#| label: pct-faltantes-sin-sector
agg_pymes_df <- pymes_df |>
  mutate(across(starts_with("n_"), ~ as.numeric(na_if(.x, "SIN DATOS")))) |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  group_by(anio, departamento, tamanio) |>
  summarise(across(starts_with("n_"), ~ sum(.x, na.rm = T)), across(!starts_with("n_") & !matches("sector"), ~ mean(., na.rm=T))) |>
  mutate(across(where(is.numeric), ~ if_else(is.nan(.), NA, .)))

agg_pymes_df |>
  ungroup() |>
  filter(tamanio != "grandes") |>
  select(!c(anio:tamanio)) |>
  pivot_longer(everything(), names_to="variable", values_to="cant_faltantes") |>
  mutate(cant_faltantes = if_else(is.na(cant_faltantes), 1, 0)) |>
  group_by(variable) |>
  summarise(cant_faltantes = sum(cant_faltantes)) |>
  mutate(pct_faltantes = cant_faltantes * 100 / nrow(agg_pymes_df)) |>
  mutate(variable = fct_reorder(variable, cant_faltantes)) |>
  ggplot(aes(x=variable, y=pct_faltantes)) +
  geom_col(fill="skyblue") +
  labs(
    title="Porcentajes de datos faltantes por variable sobre el total de observaciones.",
    subtitle="Aperturado por año, departamento y tamaño.",
    x="Variable",
    y="Porcentaje de faltantes"
  ) +
  coord_flip()
```

Podemos concluir que al estar tan desagregado nuestro Dataset los datos faltantes pasan a ser un problema a tener en cuenta. A partir de este punto realizaremos nuestro análisis con el dataset aperturado por año, departamento y tamaño.

-   ¿Cómo se comportan las distintas variables numéricas por tamaño de la empresa? ¿Cómo es su distribución? ¿Y el apartamiento?

```{r}
#| label: dist-num-vars
agg_pymes_df |>
  ungroup() %>%
  split(f=.$tamanio) |>
  lapply(\(x) x |> summarise(across(where(is.numeric), .fns=list(
    min=~min(., na.rm=T),
    p25 = ~quantile(., 0.25, na.rm=T),
    mediana = ~median(., na.rm=T),
    media = ~mean(., na.rm=T),
    p75 = ~quantile(., 0.75, na.rm=T),
    max=~max(., na.rm=T),
    std_dev = ~sd(., na.rm=T),
    std_err = ~sd(., na.rm=T)/sqrt(n()),
    cv=~100*(sd(., na.rm=T)/mean(., na.rm=T))
  ), .names = "{.col}-{.fn}")) |>
    pivot_longer(everything(), names_sep="-", names_to=c("variable", ".value")))
```

*Visualmente*:

-   Variables sobre Pymes

```{r}
#| label: dist-num-vars-pymes-plots
agg_pymes_df |>
  ungroup() %>%
  split(f=.$tamanio) |>
  lapply(\(x) x |>
           select(tamanio, starts_with("n_")) |>
           pivot_longer(-tamanio, names_to="variable", values_to="valor") |>
           ggplot(aes(x=variable, y=log10(valor))) +
           geom_violin(fill="#0000FF") +
           geom_boxplot(width=0.31, alpha=1, fill="#FFA500"))
```

-   Variables sobre socio-educativas

```{r}
#| label: dist-num-vars-socio-educ-plots
socio_educ_vars <- c("alfabetismo", "accesos_a_estudios_terciarios", "anios_de_educacion_promedio", "promocion_educacion_media_cb", "acceso_a_internet", "porcentaje_de_personal_presupuestado_en_la_intendencia")
agg_pymes_df |>
  ungroup() %>%
  split(f=.$tamanio) |>
  lapply(\(x) x |>
           select(tamanio, all_of(socio_educ_vars)) |>
           pivot_longer(-tamanio, names_to="variable", values_to="valor") |>
           ggplot(aes(x=variable, y=valor)) +
           geom_violin(fill="#0000FF") +
           geom_boxplot(width=0.21, alpha=1, fill="#FFA500"))
```

-   Variables económicas:

```{r}
#| label: dist-num-vars-econ-plots
econ_vars <- c("pobreza", "informalidad", "desempleo_en_jovenes", "gini", "ingresos_de_los_hogares", "tasa_de_desempleo")
agg_pymes_df |>
  ungroup() %>%
  split(f=.$tamanio) |>
  lapply(\(x) x |>
           select(tamanio, all_of(econ_vars)) |>
           pivot_longer(-tamanio, names_to="variable", values_to="valor") |>
           ggplot(aes(x=variable, y=valor)) +
           geom_violin(fill="#0000FF") +
           geom_boxplot(width=0.26, alpha=1, fill="#FFA500"))
```

-   ¿Cómo se relacionan las distintas variables numéricas con la cantidad de empresas?

    -   Con las variables socio-educativas

```{r}
#| label: interaccion-n-empresas-vars-educ
agg_pymes_df |>
  mutate(n_empresas = log(n_empresas)) |>
  GGally::ggpairs(columns=c("n_empresas", socio_educ_vars), aes(color=tamanio, alpha=.5), progress = F) |>
  print() |>
  suppressWarnings()
```

-   Con las variables economicas:

```{r}
#| label: interaccion-n-empresas-econ-vars
agg_pymes_df |>
  GGally::ggpairs(columns=c("n_empresas", econ_vars), aes(color=tamanio, alpha=.5), progress = F) |>
  print() |>
  suppressWarnings()
```

-   ¿Cómo evolucionan los variables de pymes a lo largo de los años?

```{r}
pymes_df |>
  mutate(across(starts_with("n_"), ~ as.numeric(na_if(.x, "SIN DATOS")))) |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  select(-sector, -departamento, -tamanio) |>
  group_by(anio) |>
  summarise(across(starts_with("n_"), ~ sum(.x, na.rm=T))) |>
  ungroup() |>
  mutate(anio = as.numeric(as.character(anio))) |>
  pivot_longer(-anio, names_to="variable", values_to="valor") |>
  ggplot(aes(x=anio, y=valor, color=variable)) +
  geom_line() +
  labs(
    title="Evolución de la cantidad de empresas, muertes y nacimientos.",
    subtitle="A nivel nacional y por año.",
    x="Año",
    y="Cantidad"
  )
```

-   ¿Y por tamaño de la empresa?

```{r}
pymes_df |>
  mutate(across(starts_with("n_"), ~ as.numeric(na_if(.x, "SIN DATOS")))) |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  select(-sector, -departamento) |>
  group_by(anio, tamanio) |>
  summarise(across(starts_with("n_"), ~ sum(.x, na.rm=T))) |>
  ungroup() |>
  mutate(anio = as.numeric(as.character(anio))) |>
  pivot_longer(c(-anio, -tamanio), names_to="variable", values_to="valor") |>
  ggplot(aes(x=anio, y=valor, color=variable)) +
  geom_line() +
  facet_wrap(~ tamanio, scales="free") +
  labs(
    title="Evolución de la cantidad de empresas, muertes y nacimientos.",
    subtitle="A nivel nacional, por año y sector.",
    x="Año",
    y="Cantidad"
  )
```

## Preprocesamiento de datos

Como se pudo observar durante la fase del EDA, nuestro dataset crudo tiene problema de consistencia e incompletitud en los datos que, en ésta sección, abordaremos para transformarlo hacia un dataset que nos permita realizar una predicción lo más confiable posible.

Débido a esto es que realizaremos las siguientes transformaciones antes de modelar:

-   Utilizaremos año, departamento y tamaño como apertura.
-   Transformaremos todos los datos faltantes a NA.
-   Redondearemos a 3 decimales las variables numéricas.
-   Utilizaremos la serie sin datos faltantes (2008-2018)

```{r}
series_df <- pymes_df |>
  mutate(across(starts_with("n_"), ~ as.numeric(na_if(.x, "SIN DATOS")))) |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  group_by(anio, departamento, tamanio) |>
  summarise(across(starts_with("n_"), ~ sum(.x, na.rm = T)), across(!starts_with("n_") & !matches("sector"), ~ mean(., na.rm=T))) |>
  mutate(across(where(is.numeric), ~ if_else(is.nan(.), NA, .))) |>
  ungroup() |>
  filter(as.numeric(anio) < 2019)
```

## Modelado

Es de nuestro interés la creación de un modelo predictivo de la variable `n_empresas` y, para cumplir con dicho objetivo, utilizaremos el resto de variables como predictores de `n_empresas` tratando de modelar cómo la situación educacional, social y económica de cada departamento influye en la creación de Pymes.

Empezaremos estableciendo un punto de partida con un modelo "baseline" que queremos superar con modelos más complejos que sepan inferir las relaciones complejas en éste problema multidimensional.

### Separación en datos de entrenamiento y de validación

En un problema de predicción, la separación de entrenamiento difiere un poco de lo que se hace para una regresión ya que al querer generar un modelo que predice el futuro nuestra validación reside en que tan bien éste predice en comparación a un evento que realmente ocurrió.

Una práctica común al momento de hacer ésta separación de datos es la de separar basados en tu horizonte de predicción (cuantos puntos a futuro se quiere predecir).
Utilizando ésta referencia es que utilizaremos el 2017 como punto de separación

```{r}
#| label: data-splitting
train_df <- series_df |> filter(as.numeric(anio) <= 2017)
test_df <- series_df |> filter(as.numeric(anio) > 2017)

series_df |>
  mutate(set = if_else(as.numeric(anio) <= 2017, "train", "test")) |>
  filter(departamento == "montevideo") |>
  ggplot(aes(x=as.Date(paste0(anio, "-01-01")), y=n_empresas, color=set)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ tamanio, scales="free")
```


### Regresión lineal

Para nuestro modelo base, eligiremos una regresión lineal como nuestro modelo base. Éste es un modelo básico al momento de capturar relaciones complejas o no lineales ya que se basa en la estimación de nuestra variable de interés (y) dada la sumatoria del resto de predictores ($x_i$) por un coeficiente ($b_i$) y un error ($$\varepsilon_i$$), tal que:

$$
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
$$


```{r}
lm_recipe <- recipe(n_empresas ~ ., data=train_df) |>
  step_scale(n_muertes, n_nacimientos) |>
  step_corr(all_numeric_predictors()) |>
  step_ordinalscore(tamanio)
lm_model <- linear_reg() |>
  set_engine("glm") |>
  set_mode("regression")
wf_linear <- workflow() |>
  add_model(lm_model) |>
  add_recipe(lm_recipe)

lm_fit <- fit(wf_linear, data=train_df)
lm_preds <- predict(lm_fit, test_df)
lm_preds
```


### Referencias

::: {#refs}
:::
